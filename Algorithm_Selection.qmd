---
title: "Algorithm Selection"
format: pdf
editor: visual
jupyter: python3
---


```{python}
#Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
 
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
```

```{python}
#| echo: false

#Read the dataset
data=pd.read_csv(r'C:\Users\Laptop\OneDrive\Desktop\winequality-white.csv', sep=r';')



# Check the column names
print(data.columns)


 
#Display the first five rows
print(data.head())


data.groupby('quality').count()

#Check for null values
print(data.isnull().sum())


#Check data types
data.dtypes

```


```{python}
#| echo: false

# Transform data

def label_encoder(y):
    le = LabelEncoder()
    data[y] = le.fit_transform(data[y])
 
label_list = ["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"]
 
for l in label_list:
    label_encoder(l)
 
#Display transformed data
data.head()


# Split the data into training and testing sets:

#Divide the dataset into independent and dependent variables
X = data.drop(["quality"],axis=1)
y = data['quality']
# Assuming y is your target variable

#Split the data into training and testing set
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,
                                               random_state=42, shuffle=True) 
```

### Data was splitted as 80% train data and 20% test data.

```{python}
#| echo: false
y_train = y_train.values.reshape(-1,1)
y_test = y_test.values.reshape(-1,1)
 
print("X_train shape:",X_train.shape)
print("X_test shape:",X_test.shape)
print("y_train shape:",y_train.shape)
print("y_test shape:",y_test.shape)

```
## Standardize the data

Where applicable, we will perform feature scaling to rescale data to have a mean of 0 and standard deviation of 1 (unit variance):

```{python}
#| echo: false

#Feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

```



We will build all six classification models and compare their accuracy scores.


```{python}
#| echo: false
#To store results of models, we create two dictionaries
result_dict_train = {}
result_dict_test = {}
```




1. Logistic Regression


```{python}
#| echo: false
#| error: true
#| warning: true

# Reshape y_train into a 1D array
y_train = np.ravel(y_train)

from sklearn.linear_model import LogisticRegression

from sklearn.preprocessing import StandardScaler

# Scale the input features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

reg = LogisticRegression(random_state = 42, max_iter=1000)
accuracies = cross_val_score(reg, X_train, y_train, cv=5)
reg.fit(X_train,y_train)
y_pred = reg.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",reg.score(X_test,y_test))


#Store results in the dictionaries
result_dict_train["Logistic Train Score"] = np.mean(accuracies)
result_dict_test["Logistic Test Score"] = reg.score(X_test,y_test)

```


 2. KNN Classifier


```{python}
#| echo: false

knn = KNeighborsClassifier()
accuracies = cross_val_score(knn, X_train, y_train, cv=5)
knn.fit(X_train,y_train)
y_pred = knn.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",knn.score(X_test,y_test))


#Store results in the dictionaries
result_dict_train["KNN Train Score"] = np.mean(accuracies)
result_dict_test["KNN Test Score"] = knn.score(X_test,y_test)
```



 3. Support Vector Classifier

```{python}
#| echo: false

svc = SVC(random_state = 42)
accuracies = cross_val_score(svc, X_train, y_train, cv=5)
svc.fit(X_train,y_train)
y_pred = svc.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",svc.score(X_test,y_test))


#Store results in the dictionaries
result_dict_train["SVM Train Score"] = np.mean(accuracies)
result_dict_test["SVM Test Score"] = svc.score(X_test,y_test) 

```      



4. Decision Tree Classifier

```{python}
#| echo: false

dtc = DecisionTreeClassifier(random_state = 42)
accuracies = cross_val_score(dtc, X_train, y_train, cv=5)
dtc.fit(X_train,y_train)
y_pred = dtc.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",dtc.score(X_test,y_test))



#Store results in the dictionaries
result_dict_train["Decision Tree Train Score"] = np.mean(accuracies)
result_dict_test["Decision Tree Test Score"] = dtc.score(X_test,y_test)
```

5. Random Forest Classifier

```{python}
#| echo: false
#| warning: false
#| message: false


rfc = RandomForestClassifier(random_state = 42)
accuracies = cross_val_score(rfc, X_train, y_train, cv=5)
rfc.fit(X_train,y_train)
y_pred = rfc.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",rfc.score(X_test,y_test))


#Store results in the dictionaries
result_dict_train["Random Forest Train Score"] = np.mean(accuracies)
result_dict_test["Random Forest Test Score"] = rfc.score(X_test,y_test)

```



6. Na√Øve Bayes Classifier



```{python}
#| echo: false

gnb = GaussianNB()
accuracies = cross_val_score(gnb, X_train, y_train, cv=5)
gnb.fit(X_train,y_train)
y_pred = gnb.predict(X_test)
 
#Obtain accuracy
print("Train Score:",np.mean(accuracies))
print("Test Score:",gnb.score(X_test,y_test))


#Store results in the dictionaries
result_dict_train["Gaussian NB Train Score"] = np.mean(accuracies)
result_dict_test["Gaussian NB Test Score"] = gnb.score(X_test,y_test)

```


### Comparing Accuracy Scores


```{python}
#| echo: false

df_result_train = pd.DataFrame.from_dict(result_dict_train,orient = "index", columns=["Score"])
df_result_train

```


```{python}
#| echo: false

df_result_test = pd.DataFrame.from_dict(result_dict_test,orient = "index",columns=["Score"])
df_result_test
```


### Visualizing the scores

```{python}
#| echo: false
import seaborn as sns
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 2, figsize=(20, 5))
sns.barplot(x=df_result_train.index, y=df_result_train.Score, ax=ax[0])
sns.barplot(x=df_result_test.index, y=df_result_test.Score, ax=ax[1])

# Set ticks and labels
ax[0].set_xticks(range(len(df_result_train.index)))
ax[0].set_xticklabels(df_result_train.index, rotation=75)
ax[1].set_xticks(range(len(df_result_test.index)))
ax[1].set_xticklabels(df_result_test.index, rotation=75)

plt.show()

```
